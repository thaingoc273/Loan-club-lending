rm(list = ls())
libraries_used <-
c("lazyeval", "readr","plyr" ,"dplyr", "readxl", "ggplot2",
"funModeling", "scales", "tidyverse", "corrplot", "GGally", "caret",
"rpart", "randomForest", "pROC", "gbm", "choroplethr", "choroplethrMaps",
"microbenchmark", "doParallel", "e1071")
# check missing libraries
libraries_missing <-
libraries_used[!(libraries_used %in% installed.packages()[,"Package"])]
# install missing libraries
if(length(libraries_missing)) install.packages(libraries_missing)
library(plyr)
library(tidyverse)
library(caret)
library(scales)
library(corrplot)
library(fastDummies)
#install.packages("DescTools")
library(DescTools)
library(readxl)
library(xgboost)
data<-readr::read_csv("loan.csv")
rm(list = ls())
libraries_used <-
c("lazyeval", "readr","plyr" ,"dplyr", "readxl", "ggplot2",
"funModeling", "scales", "tidyverse", "corrplot", "GGally", "caret",
"rpart", "randomForest", "pROC", "gbm", "choroplethr", "choroplethrMaps",
"microbenchmark", "doParallel", "e1071")
# check missing libraries
libraries_missing <-
libraries_used[!(libraries_used %in% installed.packages()[,"Package"])]
# install missing libraries
if(length(libraries_missing)) install.packages(libraries_missing)
library(plyr)
library(tidyverse)
library(caret)
library(scales)
library(corrplot)
library(fastDummies)
#install.packages("DescTools")
library(DescTools)
library(readxl)
library(xgboost)
data<-readr::read_csv("loan.csv")
col_unique_remove <-function()
{
list_name=list()
for (i in 1:ncol(data))
{
if(nrow(unique(data[,i]))==1)
{
list_name=c(list_name, colnames(data)[i])
}
}
list_name
}
list_columname_remove<-col_unique_remove()
data<-data[, !(colnames(data) %in% list_columname_remove)]
meta_data <- funModeling::df_status(data)
meta_data<-meta_data %>% mutate(unique_rat = unique /nrow(data))
knitr::kable(meta_data)
data_remove_highNA <- function(ratio)
{
for (i in 1:nrow(meta_data))
{
if (meta_data[i, "p_na"]>ratio)
{
data[meta_data[i,"variable"]]<-list(NULL)
}
}
data
}
data = data_remove_highNA(94)
# Update meta data
meta_data <- funModeling::df_status(data)
remove_rows <-function(number)
{
list_name=list()
for (i in 1:nrow(meta_data))
{
if ((meta_data[i,"q_na"]<number)&(meta_data[i,"q_na"]>0))
{
list_name = c(list_name, meta_data[i,"variable"])
}
}
list_name
}
list_name=remove_rows(200)
data = drop_na(data, rapply(list_name, c))
col_name_NA_small_rate <- function (rate)
{
list_name = list()
for (i in 1:nrow(meta_data))
{
if ((meta_data[i, "q_na"]>0)&(meta_data[i,"p_na"]<rate)&(lapply(data[meta_data[i,"variable"]], class)=="numeric"))
{
#print(meta_data[i, "p_na"])
list_name = c(list_name, meta_data[i, "variable"])
}
}
list_name
}
list_name_NA_small = col_name_NA_small_rate(4)
data <-
data %>%
mutate_at(.vars = rapply(list_name_NA_small, c), .funs = funs(replace(., is.na(.), 0)))
chr_to_date_vars <-
c("issue_d", "last_pymnt_d", "last_credit_pull_d",
"next_pymnt_d", "earliest_cr_line")
convert_date <- function(x){
as.Date(paste0("01-", x), format = "%d-%b-%Y")
}
data <-
data %>%
mutate_at(.funs = funs(convert_date), .vars = chr_to_date_vars)
meta_data <- funModeling::df_status(data)
col_name_NA_numeric <- function ()
{
list_name = list()
for (i in 1:nrow(meta_data))
{
if ((meta_data[i, "q_na"]>0)&(lapply(data[meta_data[i,"variable"]], class)=="numeric"))
{
list_name = c(list_name, meta_data[i, "variable"])
}
}
list_name
}
list_name_NA_numeric <- col_name_NA_numeric()
data <-
data %>%
mutate_at(.vars = rapply(list_name_NA_numeric, c), .funs = funs(replace(., is.na(.), 0)))
col_name_NA_char <- function()
{
list_name=list()
for (i in 1: nrow(meta_data))
{
if((meta_data[i, "q_na"]>0)&(lapply(data[meta_data[i,"variable"]], class)=="character"))
{
list_name=c(list_name, meta_data[i, "variable"])
}
}
list_name
}
list_name_NA_char <- col_name_NA_char()
data <-
data %>%
mutate_at(.vars = rapply(list_name_NA_char, c), .funs = funs(replace(., is.na(.), "Other")))
data$last_pymnt_d <- ifelse(is.na(data$last_pymnt_d), data$issue_d, data$last_pymnt_d)
data$next_pymnt_d <- ifelse((is.na(data$next_pymnt_d)&(data$term =="36 months")), data$issue_d +365*3,data$next_pymnt_d)
data$next_pymnt_d <- ifelse((is.na(data$next_pymnt_d)&(data$term =="60 months")), data$issue_d + 365*5,data$next_pymnt_d)
data$last_pymnt_d <- as.Date(data$last_pymnt_d, origin = "1970-01-01")
data$next_pymnt_d <- as.Date(data$next_pymnt_d, origin = "1970-01-01")
meta_data <- funModeling::df_status(data)
col_name_remv_zeros_high <- function(rate)
{
for (i in 1:nrow(meta_data))
{
if (meta_data[i, "p_zeros"]>rate)
{
data[meta_data[i, "variable"]] <- list(NULL)
}
}
data
}
data <- col_name_remv_zeros_high(95)
data["sub_grade"] <- list(NULL)
meta_data <- funModeling::df_status(data)
col_name_char_type <- function()
{
list_name <- list()
for (i in 1:nrow(meta_data))
{
if (meta_data[i, "type"]=="character")
{
list_name <- c(list_name, meta_data[i, "variable"])
}
}
list_name<-rapply(list_name, c)
}
list_col_name_char_type <-col_name_char_type()
col_name_numeric_type <- function()
{
list_name <- list()
for (i in 1:nrow(meta_data))
{
if (meta_data[i, "type"]=="numeric")
{
list_name <- c(list_name, meta_data[i, "variable"])
}
}
list_name<-rapply(list_name, c)
}
list_name_numeric = col_name_numeric_type()
#Finding name list of columns only with two unique values
list_col_name_two_classes<-list()
for (i in 1:nrow(meta_data))
{
if (meta_data[i, "unique"]==2)
list_col_name_two_classes <- c(list_col_name_two_classes, meta_data[i,"variable"])
}
#Removing columns with rate < 0.05%
for (i in 1:length(list_col_name_two_classes))
{
if(min(table(data[rapply(list_col_name_two_classes[i],c)]))/nrow(data)<0.0005)
{
data[rapply(list_col_name_two_classes[i],c)] <- list(NULL)
}
}
meta_data <- funModeling::df_status(data)
list_name_numeric <- col_name_numeric_type()
list_name_high_corre <- caret::findCorrelation(cor(data[list_name_numeric], use = "complete.obs"),
names = TRUE, cutoff = .95)
data[list_name_high_corre]<-list(NULL)
meta_data_char <- subset(meta_data, type=="character")
remv_high_card_categorical <- function(number)
{
for (i in 1:nrow(meta_data_char))
{
if(meta_data_char[i, "unique"] > number)
{
data[meta_data_char[i, "variable"]] <- list(NULL)
}
}
data
}
data <-remv_high_card_categorical(40)
meta_data <- funModeling::df_status(data)
defaulted <-
c("Charged Off",
"Default",
"Does not meet the credit policy. Status:Charged Off",
"In Grace Period",
"Late (16-30 days)",
"Late (31-120 days)")
data <-
data %>%
mutate(default = ifelse(!(loan_status %in% defaulted), FALSE, TRUE))
data["loan_status"]<-list(NULL)
table(data$default)/nrow(data)
meta_data <- funModeling::df_status(data)
meta_data<-meta_data %>% mutate(unique_rat = unique /nrow(data))
knitr::kable(meta_data)
#write.csv(data, "loan_process_final_2.csv")
#data <- readr::read_csv2("loan_process_final.csv")
#data <- data[-1]
#install.packages("fastDummies")
meta_data_char <- subset(meta_data, type=="character")
list_col_char_remv_dummy <-rapply(meta_data_char["variable"],c)
library(fastDummies)
data <- dummy_cols(data, select_columns = list_col_char_remv_dummy)
data <- data[, !(colnames(data) %in% list_col_char_remv_dummy)]
meta_data_gradboost <- meta_data <- funModeling::df_status(data)
meta_data_date <- subset(meta_data_gradboost, type =="Date")
list_colname_date <- meta_data_date["variable"]
list_colname_date <- rapply(list_colname_date, c)
for (i in 1:length(list_colname_date))
{
data[list_colname_date[[i]]] <- lapply(data[list_colname_date[[i]]], as.numeric)
}
colnames(data) <- gsub(" ", "_", colnames(data))
colnames(data) <- gsub("[[:punct:]]", "_", colnames(data))
#write.csv(data, "loan_process_final_4.csv")
data <- readr::read_csv("loan_process_final_4.csv")
set.seed(123)
train_index <-
caret::createDataPartition(y = data$default, times = 1,
p = .2, list = FALSE)
train_data <- data[train_index, ]
test_data <- data[-train_index, ]
#train_down_data <-
#  caret::downSample(x = train_data[, !(names(train_data) %in% c("default"))],
#                    y = as.factor(train_data$default), yname = "default")
train_data <-
caret::downSample(x = train_data[, !(names(train_data) %in% c("default"))],
y = as.factor(train_data$default), yname = "default")
base::prop.table(table(train_data$default))
rm(data)
glm_logistic <- glm(formula = default ~ .,
family = binomial(link = "logit"),
data = train_data, na.action = na.omit, maxit=50)
summary(glm_logistic)
predict_logistic <-
predict.glm(object = glm_logistic, newdata = test_data, type = "response")
predict_logistic <- ifelse(predict_logistic > 0.5, TRUE, FALSE)
confusionMatrix(data = as.factor(predict_logistic), reference = as.factor(test_data$default), positive = "TRUE")
model_RF <- randomForest(default~., ntree = 30, data = train_data)
#install.packages("DescTools")
library(DescTools)
library(readxl)
library(xgboost)
library(randomForest)
model_RF <- randomForest(default~., ntree = 30, data = train_data)
RF_pred <- predict(object = model_RF, newdata = test_data, type = "response")
confusionMatrix(data = as.factor(RF_pred), reference = as.factor(test_data$default), positive = "TRUE")
library(xgboost)
train_x <- train_data[, names(train_data) != "default"]
train_y <- as.logical(train_data$default)
test_x <- test_data[, names(test_data) != "default"]
test_y <- as.logical(test_data$default)
gb_train <- xgb.DMatrix(data = as.matrix(train_x), label = as.matrix(train_y))
gb_test <- xgb.DMatrix(data = as.matrix(test_x), label = as.matrix(test_y))
params <- list(max_depth = 20, eta = 0.1,
objective = "binary:logistic",
silent = 0)
watchlist <- list(train = gb_train, eval = gb_test)
bst_model <- xgb.train(params = params,
data = gb_train,
nrounds = 10,
watchlist = watchlist,
verbose = FALSE,
prediction = TRUE)
#bst <- xgb.train(param, gb_train, nrounds = 2)
saveRDS(bst_model, "gradboost.rds")
bst_model
predict_gb <- predict(bst_model, as.matrix(test_x[1:1000000,]), type = "response")
predict_gb <- ifelse(predict_gb >0.5, TRUE, FALSE )
#confusionMatrix(data =as.factor(as.data.frame(predict_gb)), reference = as.factor(as.data.frame(test_data["default"])), positive = "TRUE")
confusionMatrix(data = as.factor(predict_gb), reference = as.factor(test_y[1:1000000]))
predict_gb <- predict(bst_model, as.matrix(test_x[1000001:1808360,]), type = "response")
predict_gb <- ifelse(predict_gb >0.5, TRUE, FALSE )
#confusionMatrix(data =as.factor(as.data.frame(predict_gb)), reference = as.factor(as.data.frame(test_data["default"])), positive = "TRUE")
confusionMatrix(data = as.factor(predict_gb), reference = as.factor(test_y[1000001:1808360]))
