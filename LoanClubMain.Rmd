
Lending club loan problem:
   database: loan.csv
   
Load libraries
```{r}
rm(list = ls())
```


```{r}
libraries_used <- 
  c("lazyeval", "readr","plyr" ,"dplyr", "readxl", "ggplot2", 
    "funModeling", "scales", "tidyverse", "corrplot", "GGally", "caret",
    "rpart", "randomForest", "pROC", "gbm", "choroplethr", "choroplethrMaps",
    "microbenchmark", "doParallel", "e1071")
# check missing libraries
libraries_missing <- 
  libraries_used[!(libraries_used %in% installed.packages()[,"Package"])]
# install missing libraries
if(length(libraries_missing)) install.packages(libraries_missing)

```

```{r}
library(plyr)
library(tidyverse)
library(caret)
library(scales)
library(corrplot)
library(fastDummies)
```

```{r}
#install.packages("DescTools")
library(DescTools)
library(readxl)
library(xgboost)
library(randomForest)
```


```{r}
data<-readr::read_csv("loan.csv")
```


Remove columns with unique value (no information). 

```{r}
col_unique_remove <-function()
{
  list_name=list()
  for (i in 1:ncol(data))
  {
    if(nrow(unique(data[,i]))==1)
    {
      list_name=c(list_name, colnames(data)[i])
    }
  }
  list_name
}
```


```{r}
list_columname_remove<-col_unique_remove()
```


```{r}
data<-data[, !(colnames(data) %in% list_columname_remove)]
```

View metadata in the clear way

```{r}
meta_data <- funModeling::df_status(data)
meta_data<-meta_data %>% mutate(unique_rat = unique /nrow(data))
knitr::kable(meta_data)
```

Remove columns with high missing values (94%).

```{r}
data_remove_highNA <- function(ratio)
{
  for (i in 1:nrow(meta_data))
  {
    if (meta_data[i, "p_na"]>ratio)
    {
      data[meta_data[i,"variable"]]<-list(NULL)
    }
  }
  data
}
```

```{r}
data = data_remove_highNA(94)
```


Removing rows corresponding with column with total number of missing value < 200. The number of removed rows is 238.

```{r}
# Update meta data
meta_data <- funModeling::df_status(data)
```

```{r}
remove_rows <-function(number)
{
  list_name=list()
  for (i in 1:nrow(meta_data))
  {
    if ((meta_data[i,"q_na"]<number)&(meta_data[i,"q_na"]>0))
    {
      list_name = c(list_name, meta_data[i,"variable"])
    }  
  }
  list_name
}
```
 
```{r}
list_name=remove_rows(200)
data = drop_na(data, rapply(list_name, c))
```



Replacing missing values (NA) with O for numeric columns with small percent of NA (4%). There are 45 columns with this small rate.

```{r}
col_name_NA_small_rate <- function (rate)
{
  list_name = list()
  for (i in 1:nrow(meta_data))
  {
    if ((meta_data[i, "q_na"]>0)&(meta_data[i,"p_na"]<rate)&(lapply(data[meta_data[i,"variable"]], class)=="numeric"))
    {
      #print(meta_data[i, "p_na"])
      list_name = c(list_name, meta_data[i, "variable"])
    }
  }
  list_name
}
```

```{r}
list_name_NA_small = col_name_NA_small_rate(4)

```

```{r}
data <- 
  data %>%
  mutate_at(.vars = rapply(list_name_NA_small, c), .funs = funs(replace(., is.na(.), 0)))
```


Change datatype of columns from character to Datetime

```{r}
chr_to_date_vars <- 
  c("issue_d", "last_pymnt_d", "last_credit_pull_d",
    "next_pymnt_d", "earliest_cr_line")

convert_date <- function(x){
  as.Date(paste0("01-", x), format = "%d-%b-%Y")
  } 

data <-
  data %>%
  mutate_at(.funs = funs(convert_date), .vars = chr_to_date_vars)

```



Fill missing values of columns of numeric type with  0(Due to looking at the meaning of data)

```{r}
meta_data <- funModeling::df_status(data)
```


```{r}
col_name_NA_numeric <- function ()
{
  list_name = list()
  for (i in 1:nrow(meta_data))
  {
    if ((meta_data[i, "q_na"]>0)&(lapply(data[meta_data[i,"variable"]], class)=="numeric"))
    {
      list_name = c(list_name, meta_data[i, "variable"])
    }
  }
  list_name
}
```


```{r}

list_name_NA_numeric <- col_name_NA_numeric()
data <- 
  data %>%
  mutate_at(.vars = rapply(list_name_NA_numeric, c), .funs = funs(replace(., is.na(.), 0)))
```



Filling missing value of columns type character with "Other". This is due to looking at data description. 

```{r}
col_name_NA_char <- function()
{
  list_name=list()
  for (i in 1: nrow(meta_data))
  {
    if((meta_data[i, "q_na"]>0)&(lapply(data[meta_data[i,"variable"]], class)=="character"))
    {
      list_name=c(list_name, meta_data[i, "variable"])
    }
  }
  list_name
}
```

```{r}
list_name_NA_char <- col_name_NA_char()
data <- 
  data %>%
  mutate_at(.vars = rapply(list_name_NA_char, c), .funs = funs(replace(., is.na(.), "Other")))
```



Filling Date missing value. Column last_pymnt_d (2426 or 0.11%) with issue_d and next_pymnt_d (57%) with the due date of the loan because we expext borrower will pay at the end of the loan period.

```{r}
data$last_pymnt_d <- ifelse(is.na(data$last_pymnt_d), data$issue_d, data$last_pymnt_d)
data$next_pymnt_d <- ifelse((is.na(data$next_pymnt_d)&(data$term =="36 months")), data$issue_d +365*3,data$next_pymnt_d)
data$next_pymnt_d <- ifelse((is.na(data$next_pymnt_d)&(data$term =="60 months")), data$issue_d + 365*5,data$next_pymnt_d)
```

```{r}
data$last_pymnt_d <- as.Date(data$last_pymnt_d, origin = "1970-01-01")
data$next_pymnt_d <- as.Date(data$next_pymnt_d, origin = "1970-01-01")

```


Removing columns with high rate of zeros (95%). Data now have 98 columns

```{r}
meta_data <- funModeling::df_status(data)
```

```{r}
col_name_remv_zeros_high <- function(rate)
{
  for (i in 1:nrow(meta_data))
  {
    if (meta_data[i, "p_zeros"]>rate)
    {
      data[meta_data[i, "variable"]] <- list(NULL)
    }
  }
  data
}
```


```{r}
data <- col_name_remv_zeros_high(95)
```


Removing column "sub_grade" because there is column "grade
```{r}
data["sub_grade"] <- list(NULL)
```



Find list of column names which has datatypes "character" and "numeric"

```{r}
meta_data <- funModeling::df_status(data)
```

```{r}
col_name_char_type <- function()
{
  list_name <- list()
  for (i in 1:nrow(meta_data))
  {
    if (meta_data[i, "type"]=="character")
    {
      list_name <- c(list_name, meta_data[i, "variable"])
    }
  }
  list_name<-rapply(list_name, c)
}
```

```{r}
list_col_name_char_type <-col_name_char_type()
```


```{r}
col_name_numeric_type <- function()
{
  list_name <- list()
  for (i in 1:nrow(meta_data))
  {
    if (meta_data[i, "type"]=="numeric")
    {
      list_name <- c(list_name, meta_data[i, "variable"])
    }
  }
  list_name<-rapply(list_name, c)
}
```

```{r}
list_name_numeric = col_name_numeric_type()
```


Check columns only with 2 classes. Remove colums if percentage of minority is less than 0.05%. The model now has 95 variables


```{r}
#Finding name list of columns only with two unique values

list_col_name_two_classes<-list()
for (i in 1:nrow(meta_data))
{
  if (meta_data[i, "unique"]==2)
    list_col_name_two_classes <- c(list_col_name_two_classes, meta_data[i,"variable"])
}


#Removing columns with rate < 0.05%

for (i in 1:length(list_col_name_two_classes))
{
  if(min(table(data[rapply(list_col_name_two_classes[i],c)]))/nrow(data)<0.0005)
  {
    data[rapply(list_col_name_two_classes[i],c)] <- list(NULL)
  }
}

```


Removing columns with high corr

```{r}
meta_data <- funModeling::df_status(data)
```

```{r}
list_name_numeric <- col_name_numeric_type()
list_name_high_corre <- caret::findCorrelation(cor(data[list_name_numeric], use = "complete.obs"), 
                       names = TRUE, cutoff = .95)
```


```{r}
data[list_name_high_corre]<-list(NULL)
```


Removing columns with high cardinarity for categorical type
```{r}
meta_data_char <- subset(meta_data, type=="character")
```

```{r}

remv_high_card_categorical <- function(number)
{
  for (i in 1:nrow(meta_data_char))
  {
    if(meta_data_char[i, "unique"] > number)
    {
      data[meta_data_char[i, "variable"]] <- list(NULL)
    }
  }
  data
}
```


```{r}
data <-remv_high_card_categorical(40)
```

```{r}
meta_data <- funModeling::df_status(data)
```

Define "Default" from the data 

```{r}
defaulted <- 
  c("Charged Off",
    "Default", 
    "Does not meet the credit policy. Status:Charged Off", 
    "In Grace Period", 
    "Late (16-30 days)", 
    "Late (31-120 days)")
data <-
  data %>%
  mutate(default = ifelse(!(loan_status %in% defaulted), FALSE, TRUE))
```

Delete the loan_status column
```{r}
data["loan_status"]<-list(NULL)
```

```{r}
table(data$default)/nrow(data)
```

```{r}
meta_data <- funModeling::df_status(data)
meta_data<-meta_data %>% mutate(unique_rat = unique /nrow(data))
knitr::kable(meta_data)
```

```{r}
#write.csv(data, "loan_process_final_2.csv")
#data <- readr::read_csv2("loan_process_final.csv")
#data <- data[-1]
```


Using fastDummies package to create dummy variables from catergorical variables

```{r}
#install.packages("fastDummies")
```

Adding dummy columns to full dataset

```{r}
meta_data_char <- subset(meta_data, type=="character")
list_col_char_remv_dummy <-rapply(meta_data_char["variable"],c)
```

```{r}
library(fastDummies)
data <- dummy_cols(data, select_columns = list_col_char_remv_dummy)
```


Delete the original character columns for full data

```{r}
data <- data[, !(colnames(data) %in% list_col_char_remv_dummy)]
```



Convert Date column to numeric colum for Gradient boosting algorithm

```{r}
meta_data_gradboost <- meta_data <- funModeling::df_status(data)
```

```{r}
meta_data_date <- subset(meta_data_gradboost, type =="Date")
list_colname_date <- meta_data_date["variable"] 
list_colname_date <- rapply(list_colname_date, c)
```

```{r}
for (i in 1:length(list_colname_date))
{
  data[list_colname_date[[i]]] <- lapply(data[list_colname_date[[i]]], as.numeric)
}
```


Removing space and special characters in column names

```{r}
colnames(data) <- gsub(" ", "_", colnames(data))
colnames(data) <- gsub("[[:punct:]]", "_", colnames(data))
```

```{r}
#write.csv(data, "loan_process_final_4.csv")
#data <- readr::read_csv("loan_process_final_4.csv")
#data <- data[-1]
```

Split dataset to training and test sets

```{r}
set.seed(123)
train_index <- 
  caret::createDataPartition(y = data$default, times = 1, 
                             p = .2, list = FALSE)

train_data <- data[train_index, ]
test_data <- data[-train_index, ]
```


Down sampling to get balanced lables

```{r}
#train_down_data <- 
#  caret::downSample(x = train_data[, !(names(train_data) %in% c("default"))], 
#                    y = as.factor(train_data$default), yname = "default")

train_data <- 
  caret::downSample(x = train_data[, !(names(train_data) %in% c("default"))], 
                    y = as.factor(train_data$default), yname = "default")
base::prop.table(table(train_data$default))
```

```{r}
rm(data)
```


Logistic regression

```{r}
glm_logistic <- glm(formula = default ~ ., 
                   family = binomial(link = "logit"), 
                   data = train_data, na.action = na.omit, maxit=50)
```


```{r}
summary(glm_logistic)
```




```{r}
predict_logistic <- 
  predict.glm(object = glm_logistic, newdata = test_data, type = "response")
predict_logistic <- ifelse(predict_logistic > 0.5, TRUE, FALSE)
confusionMatrix(data = as.factor(predict_logistic), reference = as.factor(test_data$default), positive = "TRUE")
                       
```

Random forest

```{r}
model_RF <- randomForest(default~., ntree = 30, data = train_data)
```

```{r}
RF_pred <- predict(object = model_RF, newdata = test_data, type = "response")
```


```{r}
confusionMatrix(data = as.factor(RF_pred), reference = as.factor(test_data$default), positive = "TRUE")
```

Extreme gradient boosting

```{r}
library(xgboost)
```


```{r}
train_x <- train_data[, names(train_data) != "default"]
train_y <- as.logical(train_data$default)
test_x <- test_data[, names(test_data) != "default"]
test_y <- as.logical(test_data$default)

gb_train <- xgb.DMatrix(data = as.matrix(train_x), label = as.matrix(train_y))
gb_test <- xgb.DMatrix(data = as.matrix(test_x), label = as.matrix(test_y))

```



```{r}
params <- list(max_depth = 20, eta = 0.1, 
               objective = "binary:logistic",
               silent = 0)

watchlist <- list(train = gb_train, eval = gb_test)

bst_model <- xgb.train(params = params, 
                       data = gb_train, 
                       nrounds = 10, 
                       watchlist = watchlist,
                       verbose = FALSE,
                       prediction = TRUE)

#bst <- xgb.train(param, gb_train, nrounds = 2)
```

```{r}
saveRDS(bst_model, "gradboost.rds")
bst_model
```

```{r}
predict_gb <- predict(bst_model, as.matrix(test_x[1:1000000,]), type = "response")
predict_gb <- ifelse(predict_gb >0.5, TRUE, FALSE )

```




```{r}
#confusionMatrix(data =as.factor(as.data.frame(predict_gb)), reference = as.factor(as.data.frame(test_data["default"])), positive = "TRUE")

confusionMatrix(data = as.factor(predict_gb), reference = as.factor(test_y[1:1000000]))
```



```{r}
predict_gb <- predict(bst_model, as.matrix(test_x[1000001:1808360,]), type = "response")
predict_gb <- ifelse(predict_gb >0.5, TRUE, FALSE )

```




```{r}
confusionMatrix(data = as.factor(predict_gb), reference = as.factor(test_y[1000001:1808360]))
```


